* weaves

There's a journal at the end.

* Code flagging

** TODO

Something to look at later.

** IMPUTATION

An assumption made to populate fields.

* Method

** Why Enquiries become Claims

Add Claims to Enquiries. Add Outcome = 1b if Claim.

Take a snapshot of the state of all roads. Imagine they will not be
repaired in the next 30 days and 60-90 days.

Which will predict a claim.

*** Predictor

Now try and detect them again.

First, use just a very specific geographic attribute.

Lat and Long may give great accuracy but only T/T 

Remove it and use LSOA, lose accuracy but also v good. Maybe more T/F.

Remove that use characteristics of an LSOA, such IMD, number of cars,
population.

Then add more PoI, like nearness to bus stops, nearness to railway
stations, etc.

**** Features

Overall character is made of features

***** Asset

****** Static

Geographic: LSOA, PoI, LSOA-derivatives, 

Structural: object-road-condition, trunk road (aid00), road
material

****** Locality

Loading-geographic: PoI

Loading-static: road type ABC, AADT and traffic class


****** Historic

Structural-historic: defects in last month, enquiries in last month

***** Exogeneous

Environmental: weather, season

***** Enquiry/Claim

Enquiry has-a Outcome:false, Claim is-a Enquiry where Outcome:true

Enquiry has-a Asset

* Modelling

Uses br.mk as its Makefile.

** Data loading

br00.R loads samples1.q and writes to an R binary.

br0.R re-loads and creates variant data-tables and stores. Also sets of
columns in the list br0.

br1.R does elementary recursive partitioning analysis. Table name is taken as
args[1], fields to use is args[2].

** Recursive Partitioning - not encouraging

First pass at the data with R partitioning found a 2-to-1 split on distance
> 500m.

I had to up maxcompete to 8 and complexity to 0.001

*** More data

**** Permits and last month's weather

I think 90 day permits and defects might help. Previous month's weather as well.

No.

**** Future works

Re-jigged dfct and prmt. Added a cwy3 to remove mtraffic as well as
distance, width, area.

** Models

*** GBM in br7.R

Not good. Very good at predicting noclaim, ie. true negative, but very low
power (true positive). I want a high false positive rate.

Confusion Matrix and Statistics

          Reference
Prediction noclaim claim
   noclaim   16086  1018
   claim         4     7
                                          
               Accuracy : 0.9403          
                 95% CI : (0.9366, 0.9438)
    No Information Rate : 0.9401          
    P-Value [Acc > NIR] : 0.4698          
                                          
                  Kappa : 0.0123          
 Mcnemar's Test P-Value : <2e-16          
                                          
            Sensitivity : 0.0068293       
            Specificity : 0.9997514       
         Pos Pred Value : 0.6363636       
         Neg Pred Value : 0.9404818       
             Prevalence : 0.0598890       
         Detection Rate : 0.0004090       
   Detection Prevalence : 0.0006427       
      Balanced Accuracy : 0.5032903       
                                          
       'Positive' Class : claim           

Variable importance gives distance and width. a0Xwidth, a0Xdistance very
high up. Others: to drop: a0Xisdist, a0Xarea. area.

*** Different data-sets

samples1d now produces some variants.

xsamples1 - all samples 

xsamples2 - long roads >= 502

xsamples3 - short roads < 502

xsamples4 - rural

xsamples5 - urban

xsamples6 - 1000 records only from urban and long

And within those I can choose different sub-sets

Currently, I'm using xroadsc

   xroadsc - no road conditions
   xlocalr - xroadsc - no local roads
   xxwintry - xroadsc - only winter season
   xenqr - xroadsc - only the claims records

xenqr is very sparse and needs code changes to use it.

**** short roads

short roads has imd as its dominant variable.
Try dropping the other a0X and removing area.

**** xlocalr

I have evaluated xlocalr - interesting results. mage2 is important in rural
areas. 

**** xxwintryr

Just GBM results, but suggests road width is key.

*** GBM SMOTE in br9.R

build/0/hcc

**** Urban dataset

Good results! Swung it all over to False Positive. Better True
Positive. Still not out-predicting the False Negative, but erring on the
side of caution.

*** RF (ranger) SMOTE in br8.R

share/2/build/hcc

**** Urban dataset

xsamples5. Much better - clear hump on the distributions.

*** Imputation on Claims

Enquiries has more classifications of the enquiry: method, enqstatusname,
and subjectcode.

enqstatusname is prescient. It is the final state of the enquiry and would
only be available after loggeddate and followupdate.

method is who logged the call. The police or works or the public.

Subjectcode (and subjectname) are coded as urgent/permanent and others.
And have a response time encoded. These are encoded in cph_weaves.csv.

There is a priority that is derived from the subjectcode too.

Unfortunately, Claims records don't record these values. By a laborious
process, see br3.R br3a.R br2.R and impute0.q and samples1.q. I've
generated imputations and loaded them back into the database. It's a 30
minute job to impute, and it is useful to have the Claims encoded in the
source.

The priority and the response time do prove to be key indicators. But it's
probably confirmation bias.

The nearest neighbours to the claims were, 50% of the time, classed as low
priority enquiries. I should really impute from a different data-set. Maybe
add the year?

*** Models: k-fold cross-validation

Yes. I do this. It's part of training control. repeatedcv is 10 with 3
repeats.

*** Models: prescient variable

estatus0 is a prescient. I remove prescient variables as part of NZV. In
the file br3a0.R called by br3a.R

xsamples1 is predicting on it's own now.

* Journal

** Rebuilt and published code

Cross-checking that it works. Issues with PoI being null. br7 and br9
appear to work.

br8 takes such a long-time now. I'll check on k1.

** This file's Emacs file variables

[  Local Variables: ]
[  mode:text ]
[  mode:outline-minor ]
[  mode:auto-fill ]
[  fill-column: 75 ]
[  coding: iso-8859-1-unix ]
[  comment-column:50 ]
[  comment-start: "[  "  ]
[  comment-end:"]" ]
[  End: ]

